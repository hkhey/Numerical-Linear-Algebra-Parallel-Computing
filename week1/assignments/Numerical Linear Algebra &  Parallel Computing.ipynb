{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d1d5003",
   "metadata": {},
   "source": [
    "## Complexity Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a1faba",
   "metadata": {},
   "source": [
    "### Problem:\n",
    "Given an integer n, count the number of its divisors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8cac29",
   "metadata": {},
   "source": [
    "#### Description of the first solution :\n",
    "The code counts the number of divisors of a given integer n by checking all values of d between 1 and n. However, a more efficient approach is to only check divisors up to the square root of n, which can reduce the number of iterations required in the loop as we are going to see in the second solution.\n",
    "#### The number of operations executed by the first solution is:\n",
    "For each value of n, the loop runs n times, so the number of operations executed is n. Therefore, we can generalize the number of operations as O(n)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2014402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes an integer n as input and returns the number of its divisors\n",
    "\n",
    "def count_divisors(n):\n",
    "    # Initialize a variable to keep count of the divisors\n",
    "    count = 0                         \n",
    "    # Initialize a variable to start checking divisors from 1\n",
    "    d = 1\n",
    "    # Iterate through all the possible divisors of n\n",
    "    while d <= n:   \n",
    "        # If d is a divisor of n, increment the count\n",
    "        if n % d == 0:  \n",
    "            count += 1\n",
    "        # Move to the next possible divisor\n",
    "        d += 1          \n",
    "    # Return the final count of divisors\n",
    "    return count        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e428f433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6687960624694824\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "count_divisors(10000000)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec96224",
   "metadata": {},
   "source": [
    "#### Description of the second solution :\n",
    "This code uses a while loop to check divisors up to the square root of n and increments the count of divisors accordingly. The code also handles the case where the divisor n is a perfect square and counts it only once.\n",
    "#### The number of operations executed by the second solution is:\n",
    "For each value of n, the loop runs up to the square root of n. Therefore, the number of operations executed is proportional to the square root of n. We can generalize the number of operations as O($\\sqrt n$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c054cefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_divisors(n):\n",
    "    # Initialize variables to count divisors and iterate over possible divisors.\n",
    "    count = 0\n",
    "    d = 1\n",
    "    # Only check divisors up to the square root of n.\n",
    "    while d*d <= n:\n",
    "        # If d is a divisor, increment count.\n",
    "        if n % d == 0:\n",
    "            # If n/d is equal to d, only count d once. Otherwise, count both d and n/d.\n",
    "            count += 1 if n / d == d else 2\n",
    "        # Increment divisor.\n",
    "        d += 1\n",
    "    # Return count of divisors.\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d597e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001003265380859375\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "count_divisors(10000000)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7024c61",
   "metadata": {},
   "source": [
    "#### Comparison:\n",
    "As the second algorithm reduces the number of iterations required in the loop, and hence reduces the number of operations executed, we could notice that the second program is faster tha the first one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc893c8b",
   "metadata": {},
   "source": [
    "| n | Solution 1 | Solution 2 |\n",
    "|---|------------|------------|\n",
    "| 10       | 0.0009989738464355469 | 0.0                  |\n",
    "| 1000     | 0.0009999275207519531 | 0.0                  |\n",
    "| 10000000 | 2.6687960624694824| 0.001003265380859375 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7461b8d2",
   "metadata": {},
   "source": [
    "## Big-O notation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3a6e45",
   "metadata": {},
   "source": [
    "##### Given T(n) = $3n^3+2n^2+\\frac{1}{2}n+7$. \n",
    ">##### Let's prove that $T(n) = O(n^3)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b53b81",
   "metadata": {},
   "source": [
    "To prove that $T(n) = O(n^3)$, we need to show that $\\exists c,  n_{0} > 0 $ | $ T(n) ≤ c*n^3$   $\\forall n ≥ n_{0}$.\n",
    "\n",
    "Let $ n_{0} = 1$.\n",
    "\n",
    "Then, for all $n ≥  n_{0}$:\n",
    "\n",
    "$ T(n) = 3n^3 + 2n^2 + \\frac{1}{2}n + 7 $ \n",
    "> $≤ 3n^3 + 2n^3 + \\frac{1}{2}n^3 + 7n^3$ (since $n ≥ 1$, $n^2 ≤ n^3$, and $n ≤ n^3)$ \\\n",
    "> $= 12.5 n^3$ \\\n",
    "> $= c * n^3$\n",
    "\n",
    "Therefore, we have shown that $T(n) ≤ c*n^3$ $\\forall n ≥ n_{0}$,\\\n",
    "Where $c = 12.5$ and $ n_{0} = 1$. Hence, \n",
    "\n",
    "$$T(n) = O(n^3)$$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb503e8d",
   "metadata": {},
   "source": [
    "#####  Let's prove that $\\forall k \\geq 1$, $n^k$ is not $O(n^{k-1})$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90d4b84",
   "metadata": {},
   "source": [
    "Suppose that there exists some constant $C > 0$ and some value $n_0 > 0$ such that for all $n \\geq n_0$, we have:\n",
    "\n",
    "$$n^k \\leq Cn^{k-1}$$\n",
    "\n",
    "Let $n_0 = 1$, dividing both sides by $n^{k-1}$, we get:\n",
    "\n",
    "$$n \\leq C$$\n",
    "\n",
    "Now, suppose we choose $n$ to be any value greater than $C$. Then we have:\n",
    "\n",
    "$$n^k > Cn^{k-1}$$\n",
    "\n",
    "But this contradicts our initial assumption that $n^k$ is $O(n^{k-1})$. Therefore, our assumption that $n^k$ is $O(n^{k-1})$ must be false."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3265c0b6",
   "metadata": {},
   "source": [
    "## Merge sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adfa53a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(A, B):\n",
    "    merged = []\n",
    "    i, j = 0, 0\n",
    "    #comparing the elements at the current positions of the pointers, and appends the smaller one to the merged array.\n",
    "    while i < len(A) and j < len(B):\n",
    "        if A[i] < B[j]:\n",
    "            merged.append(A[i])\n",
    "            i += 1\n",
    "        else:\n",
    "            merged.append(B[j])\n",
    "            j += 1\n",
    "    #append all remaining elements of list A to the \"merged\" list\n",
    "    while i < len(A):\n",
    "        merged.append(A[i])\n",
    "        i += 1\n",
    "    #append all remaining elements of list B to the \"merged\" list\n",
    "    while j < len(B):\n",
    "        merged.append(B[j])\n",
    "        j += 1\n",
    "    return merged\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abcdc49",
   "metadata": {},
   "source": [
    "#### Complexity of the function: \n",
    "The overall complexity of the function is O(n + m), where n is the length of list A and m is the length of list B. This is because the while loop that compares and appends the elements from both lists runs for at most n+m iterations in the worst case scenario, and the two while loops that append the remaining elements of A and B to the merged list run in linear time O(n) and O(m) respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9548c3b0",
   "metadata": {},
   "source": [
    "## The master method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9b5126",
   "metadata": {},
   "source": [
    "#### Using the master method, let's analyse the complexity of merge sort\n",
    "\n",
    "The time complexity of merge sort can be expressed as:\n",
    "\n",
    "T(n) = 2T(n/2) + O(n)\n",
    "\n",
    "where T(n) is the time required to sort an array of size n.\n",
    "\n",
    "This equation means that merge sort recursively sorts two subarrays of size n/2(size of each subproblem), and then merges the two subarrays into a single sorted array of size n. The merging step takes O(n) time, which dominates the recursive calls.\n",
    "\n",
    "Using the master theorem, we can determine the time complexity of merge sort as follows:\n",
    "\n",
    "$a = 2$ (because merge sort makes two recursive calls) \\\n",
    "$b = 2$ (because the size of the subproblems is halved at each level) \\\n",
    "$d = 1$ (because the merging step takes linear time) \n",
    "\n",
    "As $a = b^d$, Then: $$T(n)= O(n logn)$$\n",
    "\n",
    "Therefore, the time complexity of merge sort is O(n log n) according to the master theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96c697f",
   "metadata": {},
   "source": [
    "#### Using the master method analyse the complexity of binary search\n",
    "\n",
    "The binary search algorithm works by repeatedly dividing the search interval in half until the target element is found or the interval is empty. The time complexity of binary search can be expressed as a recurrence relation:\n",
    "\n",
    "T(n) = T(n/2) + O(1)\n",
    "\n",
    "where T(n) is the time required to search a sorted array of size n.\n",
    "\n",
    "This equation means that binary search recursively searches one of the two subarrays of size n/2, and then performs a constant time comparison to determine whether the target element is in the left or right subarray.\n",
    "\n",
    "Using the master theorem, we can determine the time complexity of binary search as follows:\n",
    "\n",
    "$a = 1$ (because binary search makes one recursive call) \\\n",
    "$b = 2$ (because the size of the subproblems is halved at each level) \\\n",
    "$d = 0$ (because the algorithm performs constant time comparisons)\n",
    "\n",
    "As $a = b^d$, Then $$T(n) = O(log n)$$\n",
    "\n",
    "Therefore, the time complexity of binary search is O(log n) according to the master theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb037c2",
   "metadata": {},
   "source": [
    "## Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f800264e",
   "metadata": {},
   "source": [
    "Using the merge sort algorithm, we are going to sort two arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1baee69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_sort(arr1, arr2):\n",
    "    \"\"\"\n",
    "    Sorts two arrays using the merge sort algorithm.\n",
    "    \"\"\"\n",
    "    # Define the merge sort function\n",
    "    def sort(arr):\n",
    "        if len(arr) <= 1:\n",
    "            return arr\n",
    "        mid = len(arr) // 2\n",
    "        left = arr[:mid]\n",
    "        right = arr[mid:]\n",
    "        left_sorted = sort(left)\n",
    "        right_sorted = sort(right)\n",
    "        return merge(left_sorted, right_sorted)\n",
    "    \n",
    "    # Sort each array separately using merge sort\n",
    "    arr1_sorted = sort(arr1)\n",
    "    arr2_sorted = sort(arr2)\n",
    "    \n",
    "    # Call the merge function on the sorted arrays\n",
    "    return merge(arr1_sorted, arr2_sorted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5511e9",
   "metadata": {},
   "source": [
    "#### Analyse the complexity of your algorithm without using the master theorem\n",
    "\n",
    "The merge sort algorithm divides the input array into two halves repeatedly until there is only one element in each sub-array, and then merges the sorted sub-arrays together. The dividing step takes O(log n) time since the array is divided in half at each level of recursion, and the merging step takes O(n) time since each element is compared and moved at most once. Therefore, the total time complexity is O(n log n)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5657a431",
   "metadata": {},
   "source": [
    "#### Let's prove the 3 cases of the master theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb0035f",
   "metadata": {},
   "source": [
    "Intuition for the 3 cases:\n",
    "\n",
    "For a level j, the amount of work is given by the recurrence relation:\n",
    "\n",
    "$T(j) = C\\cdot n^d\\cdot \\left(\\frac{a}{b^d}\\right)^j$\n",
    "\n",
    "where C is a constant, n is the size of the problem at that level, a is the number of subproblems, b is the size ratio between the subproblems and d is the exponent of the time complexity of the work done at each level.\n",
    "\n",
    "We can classify the overall time complexity of the algorithm based on the values of a, b and d:\n",
    "### Case 1:\n",
    "If $a = b^d$, then each level of the recursion tree has the same amount of work, and we have a balanced tree. In this case, the total work done by the algorithm can be calculated as:\n",
    "\n",
    "$T(n) = \\sum_{j=0}^{\\log_b n} T(j) = \\sum_{j=0}^{\\log_b n} C\\cdot n^d\\cdot \\left(\\frac{a}{b^d}\\right)^j$\n",
    "\n",
    "Using the formula for the sum of a geometric series, we can simplify this expression to obtain:\n",
    "\n",
    "$T(n) = C\\cdot n^d\\cdot (\\log_b (n) + 1) = O(n^d\\log n)$\n",
    "\n",
    "Therefore, the time complexity of the algorithm is $O(n^d\\log n)$ in this case.\n",
    "\n",
    "### Case 2:\n",
    "For the second case where $a < b^d$, we can use the following inequality:\n",
    "\n",
    "$$\\sum_{j=0}^{\\log_b n} \\left(\\frac{a}{b^d}\\right)^j = c n^d \\cdot \\sum_{j=0}^{\\log_b n} (r)^j = cn^d \\cdot C$$\n",
    "\n",
    "Here, we used the formula for a geometric series and the fact that $a < b^d$, which implies $\\frac{a}{b^d} < 1$. Therefore, the total work is $O(n^d)$ in this case.\n",
    "\n",
    "### Case 3:\n",
    "Assume $a > b^d$, we can then simplify the work as follows:\n",
    "\n",
    "$$c\\cdot n^d \\sum_{j=0}^{\\log_b n}\\left(\\frac{a}{b^d}\\right)^j= c\\cdot n^d\\sum_{j=0}^{\\log_b n} r^j$$ where $r = \\frac{a}{b^d} > 1$\n",
    "\n",
    "By using the formula for the sum of a geometric progression, we get:\n",
    "\n",
    "$$cn^d \\cdot r^{log_b n}$$\n",
    "\n",
    "Therefore, the total work is $O(n^{log_b n})$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f153bd61",
   "metadata": {},
   "source": [
    "#### Let's analyse the complexity of bubbleSort algorithm using the Big-O notation\n",
    "In the worst case scenario, the outer loop will run for n iterations, and the inner loop will run n-1 times in the first iteration, n-2 times in the second iteration, and so on, until the last iteration where the inner loop will run only once. So the total number of iterations for the inner loop can be expressed as follows:\n",
    "(n-1) + (n-2) + ... + 3 + 2 + 1 = n(n-1)/2\n",
    "\n",
    "Therefore, the time complexity of the bubble sort algorithm can be expressed as O(n^2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86ea69ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bubbleSort(arr):  \n",
    "    n = len(arr)\n",
    "    # For loop to traverse through all element in an array\n",
    "    for i in range(n):\n",
    "        for j in range(0, n - i - 1):\n",
    "            if arr[j] > arr[j + 1]:\n",
    "                arr[j], arr[j + 1] = arr[j + 1], arr[j]\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69562161",
   "metadata": {},
   "source": [
    "## Matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f516eed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_multiplication(A, B):\n",
    "    rows_A, cols_A = len(A), len(A[0])\n",
    "    rows_B, cols_B = len(B), len(B[0])\n",
    "    if cols_A != rows_B:\n",
    "        print(\"Error: number of columns in A must equal number of rows in B\")\n",
    "        return None\n",
    "    C = [[0 for _ in range(cols_B)] for _ in range(rows_A)]\n",
    "    for i in range(rows_A):\n",
    "        for j in range(cols_B):\n",
    "            for k in range(cols_A):\n",
    "                C[i][j] += A[i][k] * B[k][j]\n",
    "    return C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3ea4d8",
   "metadata": {},
   "source": [
    "#### Let's analyse the complexity of matrix multiplication algorithm using the Big-O notation\n",
    "The overall time complexity of the algorithm is proportional to the product of the sizes of the input matrices, making it an $O(n^3)$ algorithm in the worst case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3573bad",
   "metadata": {},
   "source": [
    "#### Matrix multiplication algorithm in C.\n",
    "\#include <stdlib.h> \n",
    "\n",
    "\n",
    "\
#define n 20 \n",
    "\n",
    "double a[n][n]; \\\n",
    "double b[n][n]; \\\n",
    "double c[n][n]; \n",
    "\n",
    "int main() \\\n",
    "{ \n",
    "> for (int i = 0; i < n; i++) \n",
    ">> for (int j = 0; j < n; j++) \\\n",
    "\t\t{ \n",
    ">>> a[i][j] = (double)rand() / 1000; \\\n",
    ">>> b[i][j] = (double)rand() / 1000; \\\n",
    ">>> c[i][j] = 0; \\\n",
    "} \\\n",
    "\n",
    "\n",
    "> for (int i = 0; i < n; i++) \n",
    ">> for (int j = 0; j < n; j++) \n",
    ">>> for (int k = 0; k < n; k++) \n",
    ">>>> c[i][j] += a[i][k]*b[k][j]; \n",
    "\n",
    "\treturn 0; \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff54771",
   "metadata": {},
   "source": [
    "#### New algorithm after optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac8fe73",
   "metadata": {},
   "source": [
    "he time complexity of block matrix multiplication depends on the size of the blocks used and the size of the matrices being multiplied. Let's assume that we are using square matrices of size n x n and that we are dividing them into blocks of size b x b. Then the number of blocks in each dimension is n/b.\n",
    "\n",
    "The algorithm consists of three nested loops. The outer two loops iterate over the blocks, and the innermost loop performs the actual multiplication of two blocks. Thus, the total number of block multiplications is (n/b)³, and the time complexity of each block multiplication is O(b³). Therefore, the total time complexity of block matrix multiplication is O((n/b)³ * b³) = O(n³).\n",
    "\n",
    "However, the advantage of block matrix multiplication over the naive algorithm is that it reduces the number of cache misses by improving data locality. This can result in significant speedups in practice, especially for large matrices where the matrices do not fit into the cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f130280e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def block_matrix_multiply(A, B, block_size):\n",
    "    n = len(A)\n",
    "    C = [[0 for _ in range(n)] for _ in range(n)]\n",
    "    for i in range(0, n, block_size):\n",
    "        for j in range(0, n, block_size):\n",
    "            for k in range(0, n, block_size):\n",
    "                for ii in range(i, min(i + block_size, n)):\n",
    "                    for jj in range(j, min(j + block_size, n)):\n",
    "                        for kk in range(k, min(k + block_size, n)):\n",
    "                            C[ii][jj] += A[ii][kk] * B[kk][jj]\n",
    "    return C\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af47e3c",
   "metadata": {},
   "source": [
    "# Quizz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812f2c78",
   "metadata": {},
   "source": [
    "The time complexity for the following code is $O(n)$\n",
    "> $C = 10$ \\\n",
    "> $B = 0$ \n",
    "> ##### for i in range(n): \n",
    ">>   $B += i*C$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3113a4",
   "metadata": {},
   "source": [
    "The time complexity for the following code is $O(log_k(n))$\n",
    "\n",
    "> $i = 0$ \\\n",
    "> $B = 0$ \n",
    "> ##### while $i < n$: \n",
    ">>   $i *= k$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00c75a1",
   "metadata": {},
   "source": [
    "The time complexity for the following code is $O(n^2)$\n",
    "> ##### for i in range(n): \n",
    ">>   ##### for j in range(m):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
